"""
SciTSR ì›ë³¸ ë°ì´í„°ì…‹ì„ Trainê³¼ Validationìœ¼ë¡œ ë¶„í• 

ì›ë³¸ ë°ì´í„°(structure, chunk, img íŒŒì¼ë“¤)ë¥¼ trainê³¼ val í´ë”ë¡œ ë‚˜ëˆ•ë‹ˆë‹¤.
ë‚˜ì¤‘ì— ê°ê°ì„ LRCë¡œ ë³€í™˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ì‚¬ìš©ë²•:
    python tools/split_train_val.py \
        --scitsr_dir ./data/SciTSR \
        --split_dir train \
        --val_size 1500 \
        --shuffle
"""

import os
import sys
import shutil
import argparse
import random

sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))


def split_scitsr_dataset(
    scitsr_dir: str,
    split_dir: str = 'train',
    val_size: int = 1500,
    shuffle: bool = True,
    seed: int = 42
):
    """
    SciTSR ë°ì´í„°ì…‹ì„ Trainê³¼ Validationìœ¼ë¡œ ë¶„í• 
    
    Args:
        scitsr_dir: SciTSR ë°ì´í„°ì…‹ ë£¨íŠ¸ ë””ë ‰í† ë¦¬
        split_dir: ë¶„í• í•  ë°ì´í„°ì…‹ ë””ë ‰í† ë¦¬ (ì˜ˆ: 'train')
        val_size: Validation ë°ì´í„°ì…‹ í¬ê¸°
        shuffle: ëœë¤ ì…”í”Œ ì—¬ë¶€
        seed: ëœë¤ ì‹œë“œ
    """
    # ê²½ë¡œ ì„¤ì •
    source_dir = os.path.join(scitsr_dir, split_dir)
    train_dir = os.path.join(scitsr_dir, 'train')
    val_dir = os.path.join(scitsr_dir, 'val')
    
    # ë””ë ‰í† ë¦¬ í™•ì¸
    if not os.path.exists(source_dir):
        raise ValueError(f"Source directory not found: {source_dir}")
    
    structure_dir = os.path.join(source_dir, 'structure')
    chunk_dir = os.path.join(source_dir, 'chunk')
    img_dir = os.path.join(source_dir, 'img')
    
    if not os.path.exists(structure_dir):
        raise ValueError(f"Structure directory not found: {structure_dir}")
    
    # ì›ë³¸ train ë””ë ‰í† ë¦¬ì™€ ëŒ€ìƒ train ë””ë ‰í† ë¦¬ê°€ ê°™ì€ ê²½ìš° ì²˜ë¦¬
    if source_dir == train_dir:
        # ì›ë³¸ì„ ì„ì‹œ ë””ë ‰í† ë¦¬ë¡œ ì´ë™
        temp_dir = os.path.join(scitsr_dir, f'{split_dir}_original')
        if os.path.exists(temp_dir):
            raise ValueError(f"Temporary directory already exists: {temp_dir}. Please remove it first.")
        print(f"âš ï¸  Source and target directories are the same. Moving source to temporary directory...")
        shutil.move(source_dir, temp_dir)
        source_dir = temp_dir
        structure_dir = os.path.join(source_dir, 'structure')
        chunk_dir = os.path.join(source_dir, 'chunk')
        img_dir = os.path.join(source_dir, 'img')
    
    # Structure íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
    structure_files = sorted([
        f for f in os.listdir(structure_dir)
        if f.endswith('.json')
    ])
    
    if not structure_files:
        raise ValueError(f"No structure files found in {structure_dir}")
    
    total_files = len(structure_files)
    print(f"ğŸ“ Found {total_files} files in {source_dir}")
    
    if val_size >= total_files:
        raise ValueError(f"Validation size ({val_size}) must be less than total files ({total_files})")
    
    # ì¸ë±ìŠ¤ ìƒì„±
    indices = list(range(total_files))
    
    if shuffle:
        print(f"ğŸ”€ Shuffling with seed {seed}...")
        random.seed(seed)
        random.shuffle(indices)
    
    # Trainê³¼ Validation ì¸ë±ìŠ¤ ë¶„í• 
    val_indices = set(indices[:val_size])
    train_indices = indices[val_size:]
    
    print(f"ğŸ“Š Split:")
    print(f"   Train: {len(train_indices)} files")
    print(f"   Validation: {len(val_indices)} files")
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    for target_dir in [train_dir, val_dir]:
        for subdir in ['structure', 'chunk', 'img']:
            os.makedirs(os.path.join(target_dir, subdir), exist_ok=True)
    
    # íŒŒì¼ ì´ë™ (ë³µì‚¬ê°€ ì•„ë‹Œ ì´ë™)
    print(f"\nğŸ“ Moving files...")
    
    train_count = 0
    val_count = 0
    
    for idx, structure_file in enumerate(structure_files):
        # ê¸°ë³¸ ì´ë¦„ ì¶”ì¶œ (í™•ì¥ì ì œì™¸)
        base_name = structure_file.replace('.json', '')
        
        # íŒŒì¼ ê²½ë¡œ
        structure_src = os.path.join(structure_dir, structure_file)
        chunk_src = os.path.join(chunk_dir, f'{base_name}.chunk')
        img_src = os.path.join(img_dir, f'{base_name}.png')
        
        # ëŒ€ìƒ ë””ë ‰í† ë¦¬ ê²°ì •
        if idx in val_indices:
            target_base = val_dir
            val_count += 1
        else:
            target_base = train_dir
            train_count += 1
        
        # íŒŒì¼ ì´ë™
        # Structure íŒŒì¼
        structure_dst = os.path.join(target_base, 'structure', structure_file)
        shutil.move(structure_src, structure_dst)
        
        # Chunk íŒŒì¼ (ìˆëŠ” ê²½ìš°)
        if os.path.exists(chunk_src):
            chunk_dst = os.path.join(target_base, 'chunk', f'{base_name}.chunk')
            shutil.move(chunk_src, chunk_dst)
        
        # ì´ë¯¸ì§€ íŒŒì¼ (ìˆëŠ” ê²½ìš°)
        if os.path.exists(img_src):
            img_dst = os.path.join(target_base, 'img', f'{base_name}.png')
            shutil.move(img_src, img_dst)
        
        # ì§„í–‰ ìƒí™© ì¶œë ¥
        if (train_count + val_count) % 100 == 0:
            print(f"   Processed {train_count + val_count}/{total_files} files...")
    
    # ì„ì‹œ ë””ë ‰í† ë¦¬ ì •ë¦¬ (ë¹„ì–´ìˆìœ¼ë©´ ì‚­ì œ)
    if source_dir != os.path.join(scitsr_dir, split_dir):
        try:
            # ë””ë ‰í† ë¦¬ê°€ ë¹„ì–´ìˆëŠ”ì§€ í™•ì¸
            if not os.listdir(structure_dir):
                os.rmdir(structure_dir)
            if os.path.exists(chunk_dir) and not os.listdir(chunk_dir):
                os.rmdir(chunk_dir)
            if os.path.exists(img_dir) and not os.listdir(img_dir):
                os.rmdir(img_dir)
            if not os.listdir(source_dir):
                os.rmdir(source_dir)
                print(f"âœ… Removed temporary directory: {source_dir}")
        except:
            pass
    
    print(f"\nâœ… Done!")
    print(f"   Train: {train_dir} ({train_count} files)")
    print(f"   Validation: {val_dir} ({val_count} files)")
    
    print(f"\nğŸ“‹ Next steps:")
    print(f"   1. Convert train dataset to LRC:")
    print(f"      python tools/convert_scitsr_to_lrc.py --scitsr_dir {scitsr_dir} --split train --output_dir ./data/lrc --output_name train_v5")
    print(f"   2. Convert validation dataset to LRC:")
    print(f"      python tools/convert_scitsr_to_lrc.py --scitsr_dir {scitsr_dir} --split val --output_dir ./data/lrc --output_name valid_v5")
    
    return train_dir, val_dir


def main():
    parser = argparse.ArgumentParser(
        description='Split SciTSR dataset into train and validation'
    )
    parser.add_argument('--scitsr_dir', type=str, required=True,
                       help='SciTSR dataset root directory')
    parser.add_argument('--split_dir', type=str, default='train',
                       help='Source directory to split (default: train)')
    parser.add_argument('--val_size', type=int, default=1500,
                       help='Number of files for validation dataset')
    parser.add_argument('--shuffle', action='store_true',
                       help='Shuffle files before splitting')
    parser.add_argument('--seed', type=int, default=42,
                       help='Random seed for shuffling')
    
    args = parser.parse_args()
    
    split_scitsr_dataset(
        scitsr_dir=args.scitsr_dir,
        split_dir=args.split_dir,
        val_size=args.val_size,
        shuffle=args.shuffle,
        seed=args.seed
    )


if __name__ == '__main__':
    main()

